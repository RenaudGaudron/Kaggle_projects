{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant Python libraries\n",
    "\n",
    "%reset -f\n",
    "\n",
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "# ML libraries\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Changing a few default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold = 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring an augmentation pipeline\n",
    "\n",
    "l=50 # Resizing parameter\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(l, l, p=1), # Resizing the picture\n",
    "        A.Normalize( # Normalising the picture\n",
    "            mean=[0, 0, 0], # Zero mean\n",
    "            std=[1, 1, 1], # Unit variance\n",
    "            p=1 # All pictures fed to the pipeline undergo this step\n",
    "        ),\n",
    "        A.HorizontalFlip(p=0.5), # 50% of the pictures fed to the pipeline are flipped horizontally\n",
    "        A.MedianBlur(blur_limit=3, always_apply=False, p=0.5)  # 50% of the pictures fed to the pipeline are blurred\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting features from all pictures\n",
    "\n",
    "# # Kaggle directory\n",
    "# dir_gen='/kaggle/input/petfinder-pawpularity-score'\n",
    "# dir_train='/kaggle/input/petfinder-pawpularity-score/train'\n",
    "# dir_test='/kaggle/input/petfinder-pawpularity-score/test'\n",
    "\n",
    "# Local directory\n",
    "dir_gen='../../../data'\n",
    "dir_train='../../../data\\\\train'\n",
    "dir_test='../../../data\\\\test'\n",
    "\n",
    "data_train=pd.read_csv(os.path.join(dir_gen, 'train.csv')) # Loading the initial data as provided by Kaggle\n",
    "data_train.set_index('Id', inplace=True) # Setting the index\n",
    "\n",
    "image_train, image_id_train, image_test, image_id_test, Y =([] for i in range(0,5)) # Initialising five lists\n",
    "\n",
    "for dirname, _, filenames in os.walk(dir_gen):  # Listing all files and directories in dir_gen\n",
    "    for filename in filenames: # Looping over the filenames\n",
    "        if filename[-3:]=='jpg': # Checking whether the file is a jpg image\n",
    "            img = cv2.imread(os.path.join(dirname, filename)) # Loading the image\n",
    "            transformed_img = transform(image=img)[\"image\"] # Transforming the image according to the transformation pipeline\n",
    "            file_index=filename.replace(\".jpg\", \"\") # The index is the file name\n",
    "            if dirname==dir_train: # If the image is in the training set\n",
    "                image_train.append(transformed_img) # Appending the image to the corresponding list\n",
    "                image_id_train.append(file_index) # Appending the image index to the corresponding list\n",
    "                Y.append(data_train.loc[pd.Index([file_index])].iloc[0][\"Pawpularity\"]/100.0) # Appending the image score to the corresponding list\n",
    "            elif dirname==dir_test: # If the image is in the testing set\n",
    "                image_test.append(transformed_img) # Appending the image to the corresponding list\n",
    "                image_id_test.append(file_index) # Appending the image index to the corresponding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (9912,)\n",
      "Shape of X: (9912, 50, 50, 3)\n",
      "Shape of X_test: (8, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Defining the feature matrices and output vector\n",
    "Y=np.asarray(Y)\n",
    "X=np.asarray(image_train)\n",
    "X_test=np.asarray(image_test)\n",
    "\n",
    "# Checking the shape of the resulting matrices\n",
    "print('Shape of Y:', Y.shape)\n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of X_test:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Convolutional Neural Network\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # A typical CNN architecture (Convolution layer, Relu activation function, MaxPooling layer repeated several times) is adopted\n",
    "    model.add(layers.Conv2D(filters=100, kernel_size=(5,5), activation='relu', input_shape=(l, l, 3)))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Conv2D(filters=100, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(keras.layers.Dense(50, activation='relu')) # Linear layer\n",
    "    model.add(layers.Dropout(0.2)) # Dropout layer\n",
    "    model.add(keras.layers.Dense(1, activation='linear')) # Linear layer\n",
    "\n",
    "    # The learning rate will be tuned using keras_tuner\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[3e-1, 1e-1, 3e-2, 1e-2, 3e-3, 1e-3, 3e-4, 1e-4])\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mse',\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hyperband tuner (from the keras_tuner library) properties\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     overwrite=True)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 01m 25s]\n",
      "val_loss: 0.04444742202758789\n",
      "\n",
      "Best val_loss So Far: 0.04175742343068123\n",
      "Total elapsed time: 00h 11m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 1 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.04175742343068123\n",
      "\n",
      "\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "try: # Removing the old folder if it exists\n",
    "    os.remove(\"/untitled_project\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Looking for the optimal hyperparameters values\n",
    "tuner.search(X, Y, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Getting the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print('\\n\\n',tuner.results_summary(num_trials=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "248/248 [==============================] - 41s 166ms/step - loss: 0.0865 - root_mean_squared_error: 0.2941 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 2/30\n",
      "248/248 [==============================] - 41s 165ms/step - loss: 0.0456 - root_mean_squared_error: 0.2136 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 3/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0447 - root_mean_squared_error: 0.2115 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2054\n",
      "Epoch 4/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0438 - root_mean_squared_error: 0.2093 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050\n",
      "Epoch 5/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0435 - root_mean_squared_error: 0.2086 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2055\n",
      "Epoch 6/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0429 - root_mean_squared_error: 0.2072 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 7/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2056\n",
      "Epoch 8/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0422 - root_mean_squared_error: 0.2054 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 9/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0405 - root_mean_squared_error: 0.2013 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 10/30\n",
      "248/248 [==============================] - 40s 161ms/step - loss: 0.0398 - root_mean_squared_error: 0.1994 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094\n",
      "Epoch 11/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0389 - root_mean_squared_error: 0.1972 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2144\n",
      "Epoch 12/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 13/30\n",
      "248/248 [==============================] - 41s 164ms/step - loss: 0.0358 - root_mean_squared_error: 0.1893 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 14/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0344 - root_mean_squared_error: 0.1855 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2216\n",
      "Epoch 15/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0326 - root_mean_squared_error: 0.1806 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 16/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0317 - root_mean_squared_error: 0.1780 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2179\n",
      "Epoch 17/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0290 - root_mean_squared_error: 0.1702 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2181\n",
      "Epoch 18/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 19/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0264 - root_mean_squared_error: 0.1626 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2220\n",
      "Epoch 20/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0245 - root_mean_squared_error: 0.1565 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2241\n",
      "Epoch 21/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2313\n",
      "Epoch 22/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 23/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0194 - root_mean_squared_error: 0.1392 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2314\n",
      "Epoch 24/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0519 - val_root_mean_squared_error: 0.2277\n",
      "Epoch 25/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0165 - root_mean_squared_error: 0.1285 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2264\n",
      "Epoch 26/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2288\n",
      "Epoch 27/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0153 - root_mean_squared_error: 0.1237 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2274\n",
      "Epoch 28/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0140 - root_mean_squared_error: 0.1182 - val_loss: 0.0521 - val_root_mean_squared_error: 0.2283\n",
      "Epoch 29/30\n",
      "248/248 [==============================] - 40s 162ms/step - loss: 0.0128 - root_mean_squared_error: 0.1131 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2274\n",
      "Epoch 30/30\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0119 - root_mean_squared_error: 0.1092 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2322\n",
      "Best epoch: 4\n"
     ]
    }
   ],
   "source": [
    "# Building the model with the best hyperparameters and training it on the data for 30 epochs. The optimal number of epochs is then selected\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, Y, epochs=30, validation_split=0.2)\n",
    "\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "248/248 [==============================] - 41s 164ms/step - loss: 0.0613 - root_mean_squared_error: 0.2477 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 2/4\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0463 - root_mean_squared_error: 0.2153 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2057\n",
      "Epoch 3/4\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0456 - root_mean_squared_error: 0.2136 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043\n",
      "Epoch 4/4\n",
      "248/248 [==============================] - 40s 163ms/step - loss: 0.0443 - root_mean_squared_error: 0.2105 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c03af126a0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the model with the best hyperparameters and optimal number of epochs\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(X, Y, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renaud\\AppData\\Local\\Temp/ipykernel_12232/1674059634.py:4: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  final_data=np.column_stack((np.transpose(image_id_test), np.transpose(Y_test).astype(np.object)*100.0))\n"
     ]
    }
   ],
   "source": [
    "Y_test = hypermodel.predict(X_test).flatten() # Predicting the output\n",
    "\n",
    "# Writing the results to a file\n",
    "final_data=np.column_stack((np.transpose(image_id_test), np.transpose(Y_test).astype(np.object)*100.0))\n",
    "np.savetxt(\"submission.csv\", final_data, delimiter=\",\", header='Id,Pawpularity', fmt='%s,%f', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
